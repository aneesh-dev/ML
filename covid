X_train = ["I'm so grateful for the amazing healthcare workers in the US who have been tirelessly fighting COVID-19. Thank you for your dedication and sacrifice.",
           "Got my second vaccine shot today! Grateful for science and the healthcare workers making this possible. Let's keep pushing for a safer future.",
           "Shoutout to the frontline workers who've been working tirelessly to keep us safe! You are the true heroes of this pandemic.",
           "The progress we've made in getting more people vaccinated is a ray of hope. Let's continue to encourage everyone to get their shots and protect our loved ones.",
           "COVID fatigue is hitting hard. It's frustrating to see some people still not taking this seriously. We can't afford to let our guard down.",
           "The misinformation and conspiracy theories about COVID are spreading faster than the virus itself. We need to trust science and experts, not baseless claims.",
           "I miss the days when I didn't have to worry about wearing a mask or keeping my distance. Let's all do our part so we can get back to normal sooner."]
# X_test = "it was really awesome and really disspntd"

y_train = ["positive","positive","positive","positive","negative","negative","negative"] # 1- Positive class, 0- negative class

X_train

from nltk.tokenize import RegexpTokenizer
# NLTK -> Tokenize -> RegexpTokenizer

from nltk.stem.porter import PorterStemmer
# NLTK -> Stem -> Porter -> PorterStemmer

from nltk.corpus import stopwords
# NLTK -> Corpus -> stopwords

# Downloading the stopwords
import nltk
nltk.download('stopwords')

tokenizer = RegexpTokenizer(r"\w+")
en_stopwords = set(stopwords.words('english'))
ps = PorterStemmer()

def getCleanedText(text):
  text = text.lower()

  # tokenizing
  tokens = tokenizer.tokenize(text)
  new_tokens = [token for token in tokens if token not in en_stopwords]
  stemmed_tokens = [ps.stem(tokens) for tokens in new_tokens]
  clean_text = " ".join(stemmed_tokens)
  return clean_text

X_test = ["it was bad"]

X_clean = [getCleanedText(i) for i in X_train]
xt_clean = [getCleanedText(i) for i in X_test]

X_clean

from sklearn.feature_extraction.text import CountVectorizer

cv = CountVectorizer(ngram_range = (1,2))

X_vec = cv.fit_transform(X_clean).toarray()

X_vec

print(cv.get_feature_names())

Xt_vect = cv.transform(xt_clean).toarray()

Xt_vect

from sklearn.naive_bayes import MultinomialNB

mn = MultinomialNB()

mn.fit(X_vec, y_train)

y_pred = mn.predict(Xt_vect)

y_pred
